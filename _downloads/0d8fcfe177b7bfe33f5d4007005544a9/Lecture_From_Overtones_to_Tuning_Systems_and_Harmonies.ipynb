{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Spectrograms & Overtones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom pitchtypes import Enharmonic, Spelled\nfrom muprocdurham import sound as s\nimport muprocdurham as mpd\n\nmpd.seed_everything(42)\n\n\n# # Spectrograms & Overtones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for f in [\"piano.wav\", \"hammond.wav\", \"piano_C.wav\", \"hammond_C.wav\"]:\n    print(f)\n    wave = s.load(f)\n    s.audio(wave)\n    s.spectrogram(wave, ylim=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "waves = []\nfor i in range(1, 15):\n    wave = s.sound(([i * 440], [np.exp(-i/2)]), duration=0.3)\n    wave = s.render(wave, normalise=False)\n    waves.append(wave)\nfor name, wave in [\n    (\"partials\", s.render(np.concatenate(waves))),\n    (\"natural tone\", s.render(sum(waves))),\n]:\n    print(name)\n    s.audio(wave)\n    s.spectrogram(wave, ylim=7000, figsize=(5, 2))\n    s.spectrogram(wave, ylim=7000, figsize=(5, 2), y_axis='log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for name, seq in [\n#     [440, 660, 880],\n    (\"Chromatic Scale\", [Enharmonic.Pitch(i).freq() for i in range(69, 82)]),\n]:\n    print(name)\n    waves = []\n    for f in seq:\n        wave = s.harmonic_tone(f, duration=0.2)\n        wave = s.render(wave)\n        waves.append(wave)\n    wave = np.concatenate(waves)\n    s.audio(wave, fade=False)\n    s.spectrogram(wave)\n\n\n# ## Piano Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_freq(f, y, ax, color, label, print_label=False, audio=False):\n    x = np.log(f)\n    ax.plot(x, y, marker='|', markersize=10, color=color)\n    ax.text(x, y + 0.03, label, fontsize=12, color=color, va='bottom', ha='center')\n    if print_label:\n        print(label)\n    if audio:\n        s.audio(s.render(s.sound(f)))\n\ndef map_to_octave(factor):\n    n = 0\n    res_factor = factor\n    while res_factor > 2:\n        res_factor /= 2\n        n += 1\n    m = 0\n    while res_factor < 1:\n        res_factor *= 2\n        m += 1\n    return n, m, res_factor\n\ndef mult_fract(factor, exponent=1, num=1, den=1):\n    if exponent > 0:\n        num *= factor ** exponent\n    if exponent < 0:\n        den *= factor ** -exponent\n    return num, den\n\ndef frac_label(factors, exponents):\n    num, den = 1, 1\n    for f, e in zip(factors, exponents):\n        num, den = mult_fract(f, e, num=num, den=den)\n    label = f\"{num}\" \n    if den > 1:\n        label += f\"/{den}\"\n    return num, den, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 5))\npitch_range = (60, 72)\n\n# plot piano keys\nblack_key_width = np.log(np.power(2, 1 / 12))\nwhite_key_width = np.log(np.power(2, 1 / 7))\nfor p in [Enharmonic.Pitch(i) for i in range(pitch_range[0], pitch_range[1] + 1)]:\n    f = np.log(p.freq())\n    c_step = ((int(p) * 7) + 1) % 12\n    if c_step < 7:\n        c = 'white'\n        width = white_key_width\n        y_offset = 0\n        z_order = 0\n        \n        chromatic_steps = int(p) % 12\n        diatonic_steps = {1:0, 3:1, 5:2, 0:3, 2:4, 4:5, 6:6}[c_step]\n        chromatic_offset = chromatic_steps * black_key_width\n        diatonic_offset = diatonic_steps * white_key_width\n        \n        x_offset = black_key_width / 2 - diatonic_offset + chromatic_offset\n    else:\n        c = 'gray'\n        width = black_key_width\n        x_offset = black_key_width / 2\n        y_offset = 0.2\n        z_order = 1\n    ax.add_patch(patches.Rectangle((f - x_offset, y_offset), width, 1 - y_offset, \n                                   linewidth=1, edgecolor='black', facecolor=c,\n                                   zorder=z_order))\n\n# set ticks and limits\nticks = [Enharmonic.Pitch(i) for i in range(pitch_range[0], pitch_range[1] + 1)]\ntick_locs = [np.log(p.freq()) for p in ticks]\ntick_names = [str(p.to_class()) for p in ticks]  # pitch classes\n# tick_names = [str(p) for p in ticks]  # with octave\nax.set_xticks(ticks=tick_locs, labels=tick_names)\nax.xaxis.set_ticks_position('top')\nax.set_xlim(min(tick_locs) - black_key_width / 2, max(tick_locs) + black_key_width / 2)\nax.set_ylim(0, 1)\nax.set_yticks([])\n\n\n# fundamental\nf0 = Enharmonic.Pitch(60).freq()\nplot_freq(f0, 0.9, ax, 'red', 'f0')\n\n# overtones\nprint(\"Overtones\")\nfor factor in [2, 3, 5, 7, 9, 11, 13]:\n    n, m, res_factor = map_to_octave(factor)\n    label = f\"{factor}\"\n    if n > 0:\n        label += f\"/{2**n}\"\n    f = f0 * res_factor\n    plot_freq(f, 0.9 - 0. * n, ax, 'red', label)\n\n# thirds and fifths (just intonation)\nprint(\"Just Intonation\")\nfor fifths_thirds, y in [\n    ([(0, 0), (1, 0), (-1, 0), (0, 1), (0, -1)], 0.75),\n    ([(2, 0), (-2, 0), (1, 1), (1, -1), (-1, -1), (-1, 1)], 0.65),\n    ([(0, 2), (0, -2), (2, 1)], 0.55),\n]:\n    for fifths, thirds in fifths_thirds:\n        factor = 3**fifths * 5**thirds\n        n, m, res_factor = map_to_octave(factor)\n        num, den, label = frac_label([3, 5, 2, 2], [fifths, thirds, -n, m])\n        plot_freq(f0 * res_factor, y, ax, 'green', label + f\"\\n({fifths},{thirds})\")\n\n# fifths (Pythagorean)\nprint(\"Pythagorean\")\nfor fifths_range, y in [(range(-6, 6), 0.4), ([12, 6], 0.2)]:\n    for fifths in fifths_range:\n        n, m, res_factor = map_to_octave(3**fifths)\n        num, den, label = frac_label([3, 2, 2], [fifths, -n, m])\n        plot_freq(f0 * res_factor, y, ax, 'blue', label + f\"\\n({fifths})\")\n\n\n# # Pitch Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compare_pitches(freqs, sequence=True, chord=True, spec=None, audio=True, **kwargs):\n    freqs = [Enharmonic.Pitch(f).freq() if isinstance(f, str) else f for f in freqs]\n    waves = [s.harmonic_tone(f, **kwargs) for f in freqs]\n    parts = []\n    if sequence:\n        parts += [s.render(w) for w in waves]\n    if chord:\n        parts += [s.render(sum(waves))]\n    wave = np.concatenate(parts)\n    if spec is not None:\n        spec_kwargs = {**dict(ylim=10000), **dict(spec)}\n        s.spectrogram(wave, **spec_kwargs)\n    if audio:\n        s.audio(wave)\n        \ndef morph(time, f1, f2, decay=1, n=20):\n    freqs = np.zeros((len(time), 2 * n))\n    amps = np.zeros_like(freqs)\n    for i in range(n):\n        freqs[:, i] = f1 * (i + 1)\n        amps[:, i] = np.exp(-i * decay) * np.linspace(1, 0, len(time))\n        freqs[:, i + n] = f2 * (i + 1)\n        amps[:, i + n] = np.exp(-i * decay) * np.linspace(0, 1, len(time))\n    return freqs, amps\n\ndef move(time, f1, f2, decay=1, n=20):\n    freqs = np.zeros((len(time), n))\n    amps = np.zeros_like(freqs)\n    for i in range(n):\n        freqs[:, i] = np.linspace(f1, f2, len(time)) * (i + 1)\n        amps[:, i] = np.exp(-i * decay)\n    return freqs, amps\n\nfor f1, f2 in [\n    (Enharmonic.Pitch(\"C4\").freq(), Enharmonic.Pitch(\"C#4\").freq()),\n    (Enharmonic.Pitch(\"C4\").freq(), Enharmonic.Pitch(\"C5\").freq()),\n]:\n    print(\"---\")\n    compare_pitches([f1, f2])\n    s.audio(s.sound(lambda time: morph(time, f1, f2), duration=5))\n    s.audio(s.sound(lambda time: move(time, f1, f2), duration=5))\n\n\n# # Tuning Systems\n\n# ## Just Intonation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f0 = Enharmonic.Pitch(\"C4\").freq()\ncompare_pitches([f0 * f for f in [1, 5/4, 3/2]])\ncompare_pitches([f0 * f for f in [1, 9/8, 5/4, 4/3, 3/2, 5/3, 15/8, 2]], chord=False, duration=0.2)\ncompare_pitches([f0 * f for f in [1, 16/15, 9/8, 6/5, 5/4, 4/3, 45/32, 3/2, 8/5, 5/3, 16/9, 15/8, 2]], chord=False, duration=0.2)\n\n\n# ## Pythagorean Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f0 = Enharmonic.Pitch(\"C4\").freq()\ncompare_pitches([f0 * f for f in [1, 81/64, 3/2]])\ncompare_pitches([f0 * f for f in [1, 9/8, 81/64, 4/3, 3/2, 27/16, 243/128, 2]], chord=False, duration=0.2)\ncompare_pitches([f0 * f for f in [1, 256/243, 9/8, 32/27, 81/64, 4/3, 1024/729, 3/2, 128/81, 27/16, 16/9, 243/128, 2]], chord=False, duration=0.2)\nprint(\"Syntonic Comma\")\ncompare_pitches([f0 * f for f in [5/4, 81/64]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lof = [Spelled.PitchClass(i) for i in range(-9, 14)]\n# for p in lof:\n#     print(f\"{p.fifths()} : {p}\")\nfor p in lof:\n    print(p.fifths(), end=\"\\t\")\nprint()\nfor p in lof:\n    print(p, end=\"\\t\")\nprint()\n\n\n# ## Equal Temperament"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f0 = Enharmonic.Pitch(\"C4\").freq()\nsemitone = np.exp(np.log(2) / 12)\ncompare_pitches([f0 * semitone ** i for i in [0, 4, 7]])\ncompare_pitches([f0 * semitone ** i for i in [0, 2, 4, 5, 7, 9, 11, 12]], chord=False, duration=0.2)\ncompare_pitches([f0 * semitone ** i for i in range(13)], chord=False, duration=0.2)\nprint(\"Pythagorean Comma\")\ncompare_pitches([f0 * f for f in [1, 531441/524288]])\n\n\n# ## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f0 = Enharmonic.Pitch(\"C4\").freq()\nprint(\"Just Intonation\")\ncompare_pitches([f0 * f for f in [1, 5/4, 3/2]], sequence=False)\ncompare_pitches([f0 * f for f in [1, 5/4, 3/2, 15/8]], sequence=False)\n# compare_pitches([f0 * f for f in [5/4, 9/8, 1, 15/8/2, 1]], chord=False, duration=0.2)\nprint(\"Pythagorean\")\ncompare_pitches([f0 * f for f in [1, 81/64, 3/2]], sequence=False)\ncompare_pitches([f0 * f for f in [1, 81/64, 3/2, 243/128]], sequence=False)\n# compare_pitches([f0 * f for f in [81/64, 9/8, 1, 243/128/2, 1]], chord=False, duration=0.2)\nprint(\"Equal Temperament\")\nsemitone = np.exp(np.log(2) / 12)\ncompare_pitches([f0 * semitone ** i for i in [0, 4, 7]], sequence=False)\ncompare_pitches([f0 * semitone ** i for i in [0, 4, 7, 11]], sequence=False)\n# compare_pitches([f0 * semitone ** i for i in [4, 2, 0, -1, 0]], chord=False, duration=0.2)\n\n\n# # Examples: Generating Sounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for func in [\n    # single frequency\n    440,\n    # multiple frequencies\n    [440, 660],\n    # changing frequency\n    lambda time: np.linspace(440, 880, len(time))[:, None],\n    # two changing frequencies\n    lambda time: np.stack([np.linspace(440, 880, len(time)),\n                           np.linspace(880, 440, len(time))], axis=-1),\n    # frequencies and amplitudes\n    lambda time: (np.stack([np.linspace(440, 880, len(time)),\n                            np.ones_like(time) * 660], axis=-1),\n                  np.stack([np.linspace(0.1, 1, len(time)),\n                            np.ones_like(time) * 0.1], axis=-1)\n                           ),\n]:\n    wave = s.sound(func=func)\n    wave = s.render(wave)\n    s.spectrogram(wave, ylim=1000)\n    s.audio(wave)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}