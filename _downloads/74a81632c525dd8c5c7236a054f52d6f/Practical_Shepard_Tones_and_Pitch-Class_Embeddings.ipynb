{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Shepard Tones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom muprocdurham import sound as s\nfrom muprocdurham import seed_everything\n\nseed_everything(42)\n\n\n# # Shepard Tones\n\n# The first part of this practical is about creating so-called *Shepard tones*, after Roger Shepard (also see https://en.wikipedia.org/wiki/Shepard_tone)\n# \n# - Shepard RN (1964) Circularity in judgments of relative pitch. The journal of the acoustical society of America 36:2346\u20132353\n# \n# A Shepard tone is an overlay of multiple sine waves separated by an octave. The amplitude is maximal for medium frequencies and smoothly goes to zero for very high and very low frequencies. As a consequence, the fundamental frequency of a Shepard tone is ambiguous, as there is not a single well-defined audible lowest frequency. In contrast, the pitch class *is* well-defined. This properties allows for a number of interesting auditory effects and illusions.\n\n# ## Creating Sounds\n\n# First, we have to be able to create sound. There are some helper functions for this in `muprocdurham.sound` (imported as `s` above), in particular `sound`, `audio`, and `spectrogram`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wave = s.sound(200, duration=1.)  # duration of 1 second is the default\ns.audio(wave)\ns.spectrogram(wave, ylim=1000)\n\n\n# In fact, this is just a very simplified example. The `sound` function really maintains a bank of oscillators for which you specify the frequency and amplitude over time. In general, you should provide a callback function that takes a NumPy array `time` (in seconds) of shape `(n,)` as input and return a pair of arrays of shape `(n, k)` with frequencies and amplitudes for each point in time (`k` is the number of oscillators used)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def freqs_amps(time):\n    freqs = [np.linspace(440, 880, len(time)),  # first oscillator continuously increases in frequency from 440 to 880Hz\n             np.ones_like(time) * 660]          # second oscillator stays at 660Hz\n    amps = [np.linspace(0.1, 1, len(time)),     # first oscillator increases in amplitude\n            np.ones_like(time) * 0.1]           # second oscillator stays at lower amplitude\n    # you can use np.stack to combine these\n    freqs = np.stack(freqs, axis=-1)\n    amps = np.stack(amps, axis=-1)\n    return freqs, amps\n\nwave = s.sound(func=freqs_amps)\ns.audio(wave)\ns.spectrogram(wave, ylim=1000)\n\n\n# For convenience, some simpler cases are supported as well, where you might not want to fully specify both arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for func in [\n    # a single constant frequency can be specified as an integer\n    440,\n    # multiple constant frequencies can be specified as a list or 1D array\n    [440, 660],\n    # if only the frequencies change, not the amplitudes, you can return a single array (make sure this is not 1D but (n, 1) for a single frequency)\n    lambda time: np.stack([np.linspace(440, 880, len(time)),\n                           np.linspace(880, 440, len(time))], axis=-1),\n    # the full case from above, just written as a single lambda function\n    lambda time: (np.stack([np.linspace(440, 880, len(time)),\n                            np.ones_like(time) * 660], axis=-1),\n                  np.stack([np.linspace(0.1, 1, len(time)),\n                            np.ones_like(time) * 0.1], axis=-1)\n                           ),\n]:\n    wave = s.sound(func=func)\n    s.audio(wave)\n    s.spectrogram(wave, ylim=1000)\n\n\n# ## Creating Shepard Tones\n\n# A Shepard tone can be specified by giving a \"fundamental\" frequency `f`, where fundamentals that differ by one or more octaves result in the same Shepard tone. The first step for creating a Shepard tone therefore is to define a function that takes a frequency `f` and returns an array of all octave-related frequencies in the audible range from 20 to 20,000Hz. A slighly more elaborate version of the function should take two additional parameters, `n` and `m`, indicating how many octaves below and above the audible range, respectively, should be additionally included (this will become relevant later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def shepard_freqs(f, n=0, m=0, min_freq=20, max_freq=20000):\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # set min/max frequency\n    min_freq = min_freq / 2**n\n    max_freq = max_freq * 2**m\n    # start at min frequency\n    while f > min_freq:\n        f /= 2\n    while f < min_freq:\n        f *= 2\n    # collect all octaves in range\n    freqs = []\n    while f <= max_freq:\n        freqs.append(f)\n        f *= 2\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    # return frequencies as 1D array\n    return np.array(freqs)\n\nprint(shepard_freqs(100))       # [   25.    50.   100.   200.   400.   800.  1600.  3200.  6400. 12800.]\nprint(shepard_freqs(100, n=1))  # [1.25e+01 2.50e+01 5.00e+01 1.00e+02 2.00e+02 4.00e+02 8.00e+02 1.60e+03 3.20e+03 6.40e+03 1.28e+04]\nprint(shepard_freqs(100, m=1))  #          [2.50e+01 5.00e+01 1.00e+02 2.00e+02 4.00e+02 8.00e+02 1.60e+03 3.20e+03 6.40e+03 1.28e+04 2.56e+04]\n\n\n# Next, we need to assign amplitudes to each frequency following a bell-shaped (e.g. Gaussian) envelope in pitch space (log-frequency space). The function should take an array of frequencies and return an array of amplituded. To adapt the shape, it should take a `max_f` and `decay` parameter specifying the frequency with maximum amplitude and how fast the amplitude decays for lower/higher frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def shepard_amps(f, max_f=500, decay=3):\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    delta = np.log(f) - np.log(max_f)  # difference in log-frequency space\n    x = delta / np.log(decay)          # decay/rescale in log-frequency space\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    return np.exp(-x**2)               # Gaussian bell\n\n# you can check the shape in frequency and log-frequency space\nf = np.linspace(1, 20000, 500)\nfig, axes = plt.subplots(1, 2, figsize=(20, 5))\naxes[0].plot(f, shepard_amps(f))\naxes[1].plot(f, shepard_amps(f))\naxes[1].set_xscale('log')\n\n\n# We can now use this to generate a Shepard tone by specifying the frequencies and amplitudes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def shepard(f, **kwargs):\n    freqs = shepard_freqs(f)\n    amps = shepard_amps(freqs)\n    return s.sound((freqs, amps), **kwargs)\n\nwave = shepard(100)\ns.audio(wave)\ns.spectrogram(wave, ylim=10000)\n\n\n# ## Effects and Illusions\n\n# ### Shepard Swipe\n\n# Because of being octave-invariant, a Shepard tone that continuously rises will be identical after one octave. Hence, it creates the illusion of an endlessly rising tone. Create a `shepard_swipe` function that starts at a specific frequency `f` and rises with a certain `speed`, repeating the full octave cycle `repeats` times.\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hints:\n\n\n- the frequency factor must change exponentially for pitch to change linearly\n- example: if `speed=2` and time is 1.5, the tone should have completed 3 cycles\n- after `n` cycles, the frequency factor should be `2**n`\n- you might want to add some extra octaves above/below so the full audible range is filled even after rising/falling\n- if you have two 1D arrays `a` and `b` with shapes `(n,)` and `(k,)`, respectively, then `a[:, None] * b[None, :]` gives you an array of shape `(n, k)` via broadcasting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def shepard_swipe(f, speed=1., repeats=1.):\n    \n    def freq_amp(time):\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        freq = shepard_freqs(f, n=repeats, m=repeats)  # add extra octaves\n        factor = 2**(time * speed)                     # compute factor for each point in time\n        freq = factor[:, None] * freq[None, :]         # use broadcasting to generate full frequency array\n        amp = shepard_amps(freq)\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        return freq, amp\n    \n    return s.sound(freq_amp, duration=repeats/np.abs(speed))\n\nwave = shepard_swipe(f=100, speed=0.1, repeats=3)\ns.audio(wave)\ns.spectrogram(wave, ylim=10000)\n\n\n# ### Shepard Swipes of Symmetric Chords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How many perfectly symmetric chords are there in 12-tone equal temperament?\n\n\n\nFor each of these chords, generate an overlay of rising/falling Shepard tones. **What do you notice concering their repeat times?**\n\n%%\nHints:\n------\n\n\n- if you `from pitchtypes import Enharmonic`, you get the frequency of, say, a C4 with `Enharmonic.Pitch(\"C4\").freq()` or `Enharmonic.Pitch(60).freq()`\n- to overlay sounds generated with the `sound` function, you can simply add them (they are just NumPy arrays with waveforms)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\nfrom pitchtypes import Enharmonic\n\nwaves = {p: shepard_swipe(f=Enharmonic.Pitch(p+\"4\").freq(), speed=0.1, repeats=2) \n         for p in [\"A\", \"C\", \"C#\", \"Eb\", \"F\", \"F#\"]}\n\ns.audio(waves[\"A\"])\ns.audio(waves[\"A\"] + waves[\"Eb\"])\ns.audio(waves[\"A\"] + waves[\"C#\"] + waves[\"F\"])\ns.audio(waves[\"A\"] + waves[\"C\"] + waves[\"Eb\"] + waves[\"F#\"])\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n# # Pitch-Class Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How does the space that musical tones live in look like?\n\n\n\nMany models of tonal space consider pitch classes, that is, they ignore the octave. There are music theoretic consideration to come up with such spaces, but in this practical, we will take a sound-based approach. Shepard tones are a great starting point because they are octave-invariant, so essentially the audible equivalent of a pitch class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ## Harmonic Shepard Tones\n\n# First, to make the sounds more similar to natural instruments, create a *harmonic Shepard tone*, that is an overlay of Shepard tones corresponding to harmonic overtones with exponentially decreasing amplitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def harmonic_shepard(f0, decay=0.1, n=20, **kwargs):\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    waves = [np.exp(-i*decay) * shepard(f0 * (i + 1), **kwargs) for i in range(0, n)]\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    return sum(waves)\n\nwave = harmonic_shepard(100)\ns.audio(wave)\ns.spectrogram(wave, ylim=10000)\n\n\n# Here is a function to compute the spectrum of a wave via Fourier transform. This can be used to compute spectral similarity. You can check the difference between a normal Shepard tone and the harmonic version below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def spectrum(wave):\n    # normalise and fade in/out\n    wave = s.render(wave, fade=dict(time=0.05))\n    # compute spectrum and ignore phases\n    fft = np.abs(np.fft.rfft(wave))\n    # do some smoothing\n    k = np.exp(-np.linspace(-3, 3, 11)**2)\n    k /= k.sum()\n    fft = np.convolve(fft, k, 'valid')\n    return fft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\naxs[0].loglog(spectrum(shepard(100)))\naxs[1].loglog(spectrum(harmonic_shepard(100)))\n\n\n# ## Pitch-Class Embeddings\n\n# Create an array of 12 `points`, corresponding to the spectra of harmonic Shepard tones of the 12 pitch classes in 12-tone equal temperament. Also store string labels in a `pitch_classes` array.\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hints:\n\n\n- order pitch classes along the line of fifths\n- the `points` array should have shape `(12, n)`, where `n` is a larger number corresponding to the resolution of the spectrum\n- use `duration=0.1` for sound generation to reduce the number of dimensions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\npitch_classes = np.array([\"F\", \"C\", \"G\", \"D\", \"A\", \"E\", \"B\", \"F#\", \"C#\", \"G#\", \"D#\", \"A#\"])\npoints = np.array([spectrum(harmonic_shepard(Enharmonic.Pitch(p+\"4\").freq(), duration=0.1)) for p in pitch_classes])\npoints.shape\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n# Embed these points into 2, 3, and 4 dimensions using UMAP and store the embeddings in a dictionary with the dimension as key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import umap\n\nembeddings = {}\nfor dim in [2, 3, 4]:\n    embeddings[dim] = umap.UMAP(n_components=dim, \n                                n_neighbors=len(points) - 1,\n                                n_epochs=10000,\n#                                 verbose=True,\n                               ).fit_transform(points)\n\n\n# ### 2D Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cycle = np.arange(len(pitch_classes) + 1) % len(pitch_classes)\nplt.plot(embeddings[2][cycle, 0], embeddings[2][cycle, 1])\nfor x, y, l in zip(embeddings[2][:, 0], embeddings[2][:, 1], pitch_classes):\n    plt.text(x, y, l)\n\n\n# ### 3D Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n\nfig = go.Figure(layout=dict(template='plotly_dark',\n                            paper_bgcolor='rgba(0,0,0,1)',\n                            plot_bgcolor='rgba(0,0,0,1)',\n#                             scene=dict(xaxis=dict(visible=False),\n#                                        yaxis=dict(visible=False),\n#                                        zaxis=dict(visible=False))\n                           ))\n\nfig.add_trace(go.Scatter3d(x=embeddings[3][cycle, 0], \n                           y=embeddings[3][cycle, 1],\n                           z=embeddings[3][cycle, 2],\n                           mode='markers+lines+text', marker=dict(size=5),\n                           text=pitch_classes,\n                           hovertemplate=\"%{text}<extra></extra>\",\n                          ))\nfig.show()\n\n\n# ### 4D Embedding\n\n# Align higher-dimensional embeddings with lower-dimensional ones to get meaningful dimensions (lower dimensions will capture more relevant structures)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def append_zeros(arr):\n    return np.concatenate([arr, np.zeros_like(arr[:, 0])[:, None]], axis=-1)\n\ndef align_point_clouds(source, target):\n    assert source.shape == target.shape, \"Point clouds must have the same dimensions.\"    \n    # Compute centroids of each point cloud\n    source_center = np.mean(source, axis=0)\n    target_center = np.mean(target, axis=0)\n    # Center the point clouds\n    source_centered = source - source_center\n    target_centered = target - target_center\n    # Compute covariance matrix\n    H = np.dot(source_centered.T, target_centered)\n    # Singular Value Decomposition (SVD)\n    U, _, Vt = np.linalg.svd(H)\n    # Compute rotation matrix\n    R = np.dot(Vt.T, U.T)\n    # Handle special case of reflection (when determinant is -1)\n    if np.linalg.det(R) < 0:\n        Vt[-1, :] *= -1\n        R = np.dot(Vt.T, U.T)\n    # Compute translation vector\n    t = target_center - np.dot(R, source_center)\n    # Apply transformation to source\n    aligned_source = np.dot(source, R.T) + t\n    return aligned_source, R, t\n\n# align and center\nfor dim, e in embeddings.items():\n    try:\n        target = append_zeros(embeddings[dim - 1])\n    except KeyError:\n        continue\n    source = e\n    aligned_source, R, t = align_point_clouds(source, target)\n    embeddings[dim] = aligned_source - np.mean(aligned_source, axis=0)\n\n\n# Plot the first two dimensions and the 3rd and 4th dimension separately. These plots suggest a circular structure. Get the angular components of the points for these two circles and plot the two phases against each other.\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What geometric shape is the product of two circles?\n\n\n\n%%\nWhen looking at neighbouring pitch classes, what structure do you see in the phase plot?\n----------------------------------------------------------------------------------------\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20, 7))\nfor ax, (x, y) in zip(axs, [\n    (embeddings[4][cycle][:, 0], embeddings[4][cycle][:, 1]),\n    (embeddings[4][cycle][:, 2], embeddings[4][cycle][:, 3]),\n    (np.arctan2(embeddings[4][cycle][:, 1], embeddings[4][cycle][:, 0]),\n     np.arctan2(embeddings[4][cycle][:, 3], embeddings[4][cycle][:, 2])),\n]):\n    ax.plot(x, y, 'o-')\n    for x_, y_, l in zip(x, y, pitch_classes[cycle]):\n        ax.text(x_, y_, l)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}