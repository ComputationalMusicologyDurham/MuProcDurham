{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Practical: Sequential Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# # Practical: Sequential Models\n\n# ## Reading in a Sequence\n\n# Write a function that extracts the MIDI pitch sequence from a music21 score and returns it as a Numpy array. Tied notes should be represented by a single pitch. If the input contains chords (notes with same onset time) it should (optionally) raise a ``RuntimeError`` or ignore them. It should be possible to provide a minimum and maximum time (in quarter beats) to specify a region of interest.\n# \n# *Hints:*\n# - ``score.flat`` is an iterable over *all* elements in the score\n# - ``m21.note.Note`` and ``m21.chord.Chord`` are base classes for single notes and chords respectively\n# - use ``element.tie`` with [``m21.tie.Tie``](https://web.mit.edu/music21/doc/moduleReference/moduleTie.html) to check for tied notes\n# - use ``element.offset`` to check for time constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import muprocdurham as mpd\nimport numpy as np\nimport music21 as m21\n\nmpd.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pitch_sequence(score, ignore_chords=True, min_time=None, max_time=None):\n    pitches = []\n    # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n    # traverse all elements in the score\n    for element in score.flat:\n        if isinstance(element, m21.note.Note) and (element.tie is None or element.tie == m21.tie.Tie(\"start\")):\n            # check for min/max time\n            if min_time is not None and element.offset < min_time:\n                continue\n            if max_time is not None and element.offset >= max_time:\n                continue\n            # get MIDI pitch for single notes\n            pitches.append(element.pitch.midi)\n        elif isinstance(element, m21.chord.Chord):\n            # ignore chords or raise error\n            if ignore_chords:\n                continue\n            raise RuntimeError(f\"Input contains chords {element} at {element.offset}\")\n        else:\n            # ignore anything else\n            continue\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    return np.asarray(pitches)\n\n\n# You can use and extend the following function to convert pitch sequences to other types if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pitchtypes import EnharmonicPitch\n\ndef convert(sequence, to):\n    if to == \"pitch classes\":\n        return np.asarray([pitch % 12 for pitch in sequence])\n    elif to == \"named pitch\":\n        return np.asarray([EnharmonicPitch(pitch) for pitch in sequence])\n    elif to == \"named pitch classes\":\n        return np.asarray([EnharmonicPitch(pitch).to_class() for pitch in sequence])\n    elif to is None:\n        return sequence\n    else:\n        raise ValueError(f\"Unknown conversion request to '{to}'\")            \n\n\n# Test your implementation on the C Major Prelude. It should start with the MIDI pitches ``[60, 64, 67, 72, 76, 67, 72, 76, 60, 64, 67, 72, 76, 67, 72, 76, ...]`` (first two bars)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score = m21.corpus.parse('bach/bwv846.mxl')\ns = pitch_sequence(score, ignore_chords=True)\n# s = convert(s, to=\"pitch classes\")\n# s = convert(s, to=\"named pitch\")\n# s = convert(s, to=\"named pitch classes\")\ns\n\n\n# ## Simple *n*-gram Model\n\n# Complete the following template class for an *n*-gram model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NGramModel:\n\n    def __init__(self, n, prior_counts=0, alphabet=()):\n        self.n = n                        # order of the n-gram model\n        self.counts = {}                  # dict with counts for the individual n-grams\n        self.prior_counts = prior_counts  # prior counts\n        self.alphabet = set(alphabet)     # alphabet of symbols\n\n    def fill_alphabet(self):\n        \"\"\"Fill gaps in integer alphabet\"\"\"\n        for a in list(range(min(self.alphabet), max(self.alphabet) + 1)):\n            self.alphabet.add(a)\n    \n    def check_n_gram(self, n_gram):\n        n_gram = tuple(n_gram)\n        assert len(n_gram) == self.n, f\"n-gram must have length n={self.n}, but {n_gram} has length {len(n_gram)}\"\n        return n_gram\n\n    def add(self, n_gram):\n        \"\"\"Add an *n*-gram by initialising or incrementing its count.\"\"\"\n        n_gram = self.check_n_gram(n_gram)\n        assert len(n_gram) == self.n, \\\n            f\"n-gram has wrong length, expected {self.n}, got {len(n_gram)}\"\n        self.alphabet |= set(n_gram)\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        try:\n            self.counts[n_gram] += 1\n        except KeyError:\n            self.counts[n_gram] = 1\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    def add_sequence(self, sequence):\n        \"\"\"Add all *n*-grams in the sequence.\"\"\"\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        for start in range(0, len(sequence) - self.n + 1):\n            n_gram = sequence[start:start + self.n]\n            self.add(n_gram)\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    def c(self, n_gram):\n        \"\"\"Return counts for this *n*-gram.\"\"\"\n        n_gram = self.check_n_gram(n_gram)\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        try:\n            return self.counts[n_gram] + self.prior_counts\n        except KeyError:\n            return self.prior_counts\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    def p(self, n_gram):\n        \"\"\"Return probability of the last element in the *n*-gram conditional on the first ``n-1`` elements.\"\"\"\n        n_gram = self.check_n_gram(n_gram)\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        norm = sum([self.c(n_gram[:-1] + (a,)) for a in self.alphabet])\n        if norm == 0:\n            return 1 / len(self.alphabet)\n        return self.c(n_gram) / norm\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n# Train a unigram model on pitch classes and plot the distribution.\n# \n# *Hint:* Use the provided function for plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from muprocdurham.ngram import show_unigram_distribution\n\ns = pitch_sequence(score=m21.corpus.parse('bach/bwv846.mxl'))\nn_gram_model = NGramModel(n=1)\n\n# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\ns = convert(s, \"pitch classes\")\nn_gram_model.add_sequence(s)\nn_gram_model.fill_alphabet()\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nprint(n_gram_model.counts)\nshow_unigram_distribution(n_gram_model, names=True, pitch_classes=True, counts=False)\n\n\n# Train a bigram model on the pitch sequence and plot\n# 1. the matrix of counts\n# 2. the matrix of transition probabilities.\n# \n# Experiment with different levels for the prior counts.\n# \n# *Hint:* Use the provided functions for creating the matrices and plotting them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from muprocdurham.ngram import bigram_matrix_from_model, show_bigram_matrix\n\n# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\ns = pitch_sequence(score=m21.corpus.parse('bach/bwv846.mxl'))\nn_gram_model = NGramModel(n=2)\nn_gram_model.add_sequence(s)\nn_gram_model.fill_alphabet()\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nfor prior_counts in [0, 5]:\n    n_gram_model.prior_counts = prior_counts\n    for mat, minmax in [\n        bigram_matrix_from_model(n_gram_model, counts=True),\n        bigram_matrix_from_model(n_gram_model),\n    ]:\n        show_bigram_matrix(mat, minmax=minmax, names=True)\n\n\n# ## Exercise by Hand\n\n# For the following sequence, count the pitch-class unigrams and bigrams and note them in a table like these:\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unigram Counts\n\n\n\n| C\u00a0\u00a0 | C#   | D\u00a0\u00a0 | D#   | E\u00a0\u00a0 | F\u00a0\u00a0 | F#   | G\u00a0\u00a0 | G#   | A\u00a0\u00a0 | A#   | B\u00a0\u00a0 |\n|----| ---- |----| ---- |----|----| ---- |----| ---- |----| ---- |----|\n|    |      |    |      |    |    |      |    |      |    |      |    |\n\n%%\nBigram Counts (rows: from; columns: to)\n---------------------------------------\n\n\n\n\n|      | C\u00a0\u00a0 | C#   | D\u00a0\u00a0 | D#   | E\u00a0\u00a0 | F\u00a0\u00a0 | F#   | G\u00a0\u00a0 | G#   | A\u00a0\u00a0 | A#   | B\u00a0\u00a0 |\n| ---- |----| ---- |----| ---- |----|----| ---- |----| ---- |----| ---- |----|\n| C    |    |      |    |      |    |    |      |    |      |    |      |    |\n| C#   |    |      |    |      |    |    |      |    |      |    |      |    |\n| D    |    |      |    |      |    |    |      |    |      |    |      |    |\n| D#   |    |      |    |      |    |    |      |    |      |    |      |    |\n| E    |    |      |    |      |    |    |      |    |      |    |      |    |\n| F    |    |      |    |      |    |    |      |    |      |    |      |    |\n| F#   |    |      |    |      |    |    |      |    |      |    |      |    |\n| G    |    |      |    |      |    |    |      |    |      |    |      |    |\n| G#   |    |      |    |      |    |    |      |    |      |    |      |    |\n| A    |    |      |    |      |    |    |      |    |      |    |      |    |\n| A#   |    |      |    |      |    |    |      |    |      |    |      |    |\n| B    |    |      |    |      |    |    |      |    |      |    |      |    |\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# s = pitch_sequence(m21.corpus.parse('bach/bwv846.mxl'), max_time=4)\ns = pitch_sequence(m21.converter.parse('./Take the A Train Theme.mid'))\n\n\nscore = m21.stream.Score()\npart = m21.stream.Part()\nmeasure = m21.stream.Measure()\nfor pitch in s:\n    measure.append(m21.note.Note(str(EnharmonicPitch(pitch)), type=\"16th\"))\npart.append(measure)\nscore.append(part)\nmpd.show_stream(score)\n\n\n# Assume the unigram and bigram counts are used in a multi-order *n*-gram model that always uses the highest-order *n*-gram possible (the one with largest n) for predicting the next note. If the melody had been generated using this model, and ignoring the octave (i.e. treating the notes as pitch classes), what are the probabilities for the respective notes?\n# \n# *Hint:* You can use the output of following to check your solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = convert(s, \"pitch classes\")\n\nunigram_model = NGramModel(n=1, alphabet=list(range(12)))\nunigram_model.add_sequence(s)\nshow_unigram_distribution(unigram_model, names=True, pitch_classes=True, counts=True)\n\nbigram_model = NGramModel(n=2, alphabet=list(range(12)))\nbigram_model.add_sequence(s)\nbigram_model.fill_alphabet()\n\nshow_bigram_matrix(*bigram_matrix_from_model(bigram_model, counts=True), show_values=True, names=True, pitch_classes=True)\n\nfor i in range(len(s)):\n    unigram = (s[i],)\n    p_unigram = unigram_model.p(unigram)\n    if i > 0:\n        bigram = s[i-1:i+1]\n        p_bigram = bigram_model.p(bigram)\n    else:\n        bigram = ()\n        p_bigram = None\n    print(f\"{EnharmonicPitch(s[i]).to_class()}: ({p_unigram}, {p_bigram})\")\n\n\n# ## Smoothing *n*-gram Model\n\n# Use the template class below to implement a smoothing *n*-gram model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SmoothingNGramModel:\n\n    def __init__(self, n, prior_counts=0, alphabet=()):\n        self._prior_counts = prior_counts\n        self.n_gram_models = {n_: NGramModel(n=n_, prior_counts=prior_counts, alphabet=alphabet) for n_ in range(1, n + 1)}\n    \n    @property\n    def prior_counts(self):\n        return self._prior_counts\n    \n    @prior_counts.setter\n    def prior_counts(self, value):\n        self._prior_counts = value\n        for model in self.n_gram_models.values():\n            model.prior_counts = value\n    \n    @property\n    def alphabet(self):\n        return set().union(*[m.alphabet for m in self.n_gram_models.values()])\n\n    def fill_alphabet(self):\n        for model in self.n_gram_models.values():\n            model.fill_alphabet()\n\n    def add_sequence(self, sequence):\n        for model in self.n_gram_models.values():\n            model.add_sequence(sequence)\n\n    def p(self, n_gram):\n        context = n_gram[:-1]\n        event = n_gram[-1]\n        n = len(n_gram)\n        w = self.weight(context)\n        # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n        n_gram_prediction = self.n_gram_models[n].p(n_gram)\n        if n == 1:\n            # stop recursion\n            return n_gram_prediction\n        else:\n            # recurse and smooth\n            return w * n_gram_prediction + (1 - w) * self.p(n_gram[1:])\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    \n    def weight(self, context):\n        return 0.5\n\n\n# Test your implementation on a simple bigram version. What effect do you observe when smoothing over bigrams and unigrams?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = pitch_sequence(score=m21.corpus.parse('bach/bwv846.mxl'))\nn_gram_model = SmoothingNGramModel(n=2)\nn_gram_model.add_sequence(s)\nn_gram_model.fill_alphabet()\n\nmat, minmax = bigram_matrix_from_model(n_gram_model)\nshow_bigram_matrix(mat, minmax=minmax, names=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}